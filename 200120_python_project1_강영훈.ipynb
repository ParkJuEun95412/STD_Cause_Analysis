{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-e3715b89c20e>\", line 4, in <module>\n",
      "    from sklearn import datasets\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\__init__.py\", line 22, in <module>\n",
      "    from ._twenty_newsgroups import fetch_20newsgroups\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py\", line 45, in <module>\n",
      "    from ..feature_extraction.text import CountVectorizer\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\__init__.py\", line 10, in <module>\n",
      "    from . import text\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 29, in <module>\n",
      "    from ..preprocessing import normalize\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py\", line 6, in <module>\n",
      "    from ._function_transformer import FunctionTransformer\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 5, in <module>\n",
      "    from ..utils.validation import _allclose_dense_sparse\n",
      "ImportError: cannot import name '_allclose_dense_sparse' from 'sklearn.utils.validation' (C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: 지정된 모듈을 찾을 수 없습니다.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-e3715b89c20e>\", line 4, in <module>\n",
      "    from sklearn import datasets\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\__init__.py\", line 22, in <module>\n",
      "    from ._twenty_newsgroups import fetch_20newsgroups\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py\", line 45, in <module>\n",
      "    from ..feature_extraction.text import CountVectorizer\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\__init__.py\", line 10, in <module>\n",
      "    from . import text\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 29, in <module>\n",
      "    from ..preprocessing import normalize\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py\", line 6, in <module>\n",
      "    from ._function_transformer import FunctionTransformer\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 5, in <module>\n",
      "    from ..utils.validation import _allclose_dense_sparse\n",
      "ImportError: cannot import name '_allclose_dense_sparse' from 'sklearn.utils.validation' (C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ICT01_04\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: 지정된 모듈을 찾을 수 없습니다.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_allclose_dense_sparse' from 'sklearn.utils.validation' (C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())\n",
    "X = iris[\"data\"][:, 3:]\n",
    "y = (iris[\"target\"] == 2).astype(np.int)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", label=\"Iris-Virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", label=\"Iris-Virginica 아님\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict([[1.7], [1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris[\"data\"][:, (2, 3)]\n",
    "y = iris[\"target\"]\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C= 10)\n",
    "softmax_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.38014896e-07, 5.74929995e-02, 9.42506362e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg.predict([[5,2]])\n",
    "softmax_reg.predict_proba([[5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>std_total</th>\n",
       "      <th>std_exp</th>\n",
       "      <th>hiv</th>\n",
       "      <th>smoke</th>\n",
       "      <th>drink</th>\n",
       "      <th>stress</th>\n",
       "      <th>depress</th>\n",
       "      <th>sex_frequency</th>\n",
       "      <th>contraception</th>\n",
       "      <th>abortion</th>\n",
       "      <th>obesity</th>\n",
       "      <th>teen_crime</th>\n",
       "      <th>tuberculosis</th>\n",
       "      <th>pre_puberty</th>\n",
       "      <th>single</th>\n",
       "      <th>private_edu</th>\n",
       "      <th>exercise3_week</th>\n",
       "      <th>basic_livelihood_security_recipient</th>\n",
       "      <th>culture_fac</th>\n",
       "      <th>welfare_fac</th>\n",
       "      <th>sports_fac</th>\n",
       "      <th>park</th>\n",
       "      <th>doctor</th>\n",
       "      <th>internet</th>\n",
       "      <th>spam_email</th>\n",
       "      <th>spam_text</th>\n",
       "      <th>rainy</th>\n",
       "      <th>tropical</th>\n",
       "      <th>heat</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>temp_low</th>\n",
       "      <th>temp_high</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>consumer_price_index</th>\n",
       "      <th>gini</th>\n",
       "      <th>cosmetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12261</td>\n",
       "      <td>66.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2875.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1419995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11563</td>\n",
       "      <td>69.279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1351185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>13164</td>\n",
       "      <td>71.193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374405.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>90.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14669</td>\n",
       "      <td>73.695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1424088.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.52</td>\n",
       "      <td>85.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16506</td>\n",
       "      <td>76.341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1513352.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.21</td>\n",
       "      <td>87.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>17.9</td>\n",
       "      <td>19399</td>\n",
       "      <td>78.444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.13</td>\n",
       "      <td>13</td>\n",
       "      <td>12.8</td>\n",
       "      <td>28.6</td>\n",
       "      <td>46.5</td>\n",
       "      <td>41.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2537.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.9</td>\n",
       "      <td>1534950.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>4.05</td>\n",
       "      <td>88.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>21727</td>\n",
       "      <td>80.202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.12</td>\n",
       "      <td>17</td>\n",
       "      <td>13.3</td>\n",
       "      <td>27.8</td>\n",
       "      <td>46.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2611.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>1549848.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.81</td>\n",
       "      <td>92.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10</td>\n",
       "      <td>75.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.26</td>\n",
       "      <td>113.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18.7</td>\n",
       "      <td>24088</td>\n",
       "      <td>82.235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4,356,287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.11</td>\n",
       "      <td>20</td>\n",
       "      <td>12.8</td>\n",
       "      <td>24.5</td>\n",
       "      <td>43.7</td>\n",
       "      <td>38.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>18.03</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>75.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>1529939.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>6.54</td>\n",
       "      <td>102.16</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.23</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>101.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>21340</td>\n",
       "      <td>86.079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,104,830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.10</td>\n",
       "      <td>27</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.1</td>\n",
       "      <td>43.2</td>\n",
       "      <td>37.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>17.33</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>1568533.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>8.37</td>\n",
       "      <td>108.19</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.31</td>\n",
       "      <td>77.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>105.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19152</td>\n",
       "      <td>88.452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,534,176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.09</td>\n",
       "      <td>28</td>\n",
       "      <td>12.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>37.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.90</td>\n",
       "      <td>2338.0</td>\n",
       "      <td>0.413820</td>\n",
       "      <td>9.2</td>\n",
       "      <td>73.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1549820.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>10.74</td>\n",
       "      <td>110.16</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.36</td>\n",
       "      <td>77.8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.05</td>\n",
       "      <td>126.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>23083</td>\n",
       "      <td>91.051</td>\n",
       "      <td>0.310</td>\n",
       "      <td>6,308,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.11</td>\n",
       "      <td>40</td>\n",
       "      <td>12.1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.97</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>0.692249</td>\n",
       "      <td>9.3</td>\n",
       "      <td>71.7</td>\n",
       "      <td>34.1</td>\n",
       "      <td>1469254.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>11.01</td>\n",
       "      <td>111.97</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.42</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.03</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>25100</td>\n",
       "      <td>94.717</td>\n",
       "      <td>0.311</td>\n",
       "      <td>6,589,773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.13</td>\n",
       "      <td>32</td>\n",
       "      <td>11.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>41.9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>77.1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>16.60</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>0.858238</td>\n",
       "      <td>9.9</td>\n",
       "      <td>69.4</td>\n",
       "      <td>33.6</td>\n",
       "      <td>1394042.0</td>\n",
       "      <td>4.28</td>\n",
       "      <td>11.61</td>\n",
       "      <td>110.74</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.47</td>\n",
       "      <td>78.4</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.04</td>\n",
       "      <td>116.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>17.6</td>\n",
       "      <td>25458</td>\n",
       "      <td>96.789</td>\n",
       "      <td>0.307</td>\n",
       "      <td>7,022,087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.11</td>\n",
       "      <td>53</td>\n",
       "      <td>9.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>41.4</td>\n",
       "      <td>30.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>14.56</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>1.065779</td>\n",
       "      <td>10.2</td>\n",
       "      <td>68.8</td>\n",
       "      <td>35.9</td>\n",
       "      <td>1350891.0</td>\n",
       "      <td>4.64</td>\n",
       "      <td>12.42</td>\n",
       "      <td>109.74</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.57</td>\n",
       "      <td>82.1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.07</td>\n",
       "      <td>110.4</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>18.4</td>\n",
       "      <td>27178</td>\n",
       "      <td>98.048</td>\n",
       "      <td>0.302</td>\n",
       "      <td>7,631,515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.13</td>\n",
       "      <td>40</td>\n",
       "      <td>9.2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>13.16</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>1.204761</td>\n",
       "      <td>10.5</td>\n",
       "      <td>68.6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>1328713.0</td>\n",
       "      <td>4.91</td>\n",
       "      <td>13.07</td>\n",
       "      <td>110.33</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.62</td>\n",
       "      <td>83.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>111.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>29242</td>\n",
       "      <td>99.298</td>\n",
       "      <td>0.302</td>\n",
       "      <td>8,177,896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.26</td>\n",
       "      <td>42</td>\n",
       "      <td>7.8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>35.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>79.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>14.05</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>1.328386</td>\n",
       "      <td>10.8</td>\n",
       "      <td>68.8</td>\n",
       "      <td>37.9</td>\n",
       "      <td>1646363.0</td>\n",
       "      <td>5.04</td>\n",
       "      <td>13.56</td>\n",
       "      <td>108.40</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.68</td>\n",
       "      <td>85.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>112.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>28724</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>9,035,455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.39</td>\n",
       "      <td>36</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>25.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>13.93</td>\n",
       "      <td>852.0</td>\n",
       "      <td>1.575468</td>\n",
       "      <td>10.8</td>\n",
       "      <td>67.8</td>\n",
       "      <td>37.7</td>\n",
       "      <td>1630614.0</td>\n",
       "      <td>5.14</td>\n",
       "      <td>14.15</td>\n",
       "      <td>112.81</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.74</td>\n",
       "      <td>88.3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>109.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>22.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>29287</td>\n",
       "      <td>100.970</td>\n",
       "      <td>0.304</td>\n",
       "      <td>9,545,681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.35</td>\n",
       "      <td>34</td>\n",
       "      <td>6.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>37.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.72</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1.800836</td>\n",
       "      <td>10.9</td>\n",
       "      <td>71.2</td>\n",
       "      <td>37.3</td>\n",
       "      <td>1581646.0</td>\n",
       "      <td>5.31</td>\n",
       "      <td>14.40</td>\n",
       "      <td>113.72</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2.82</td>\n",
       "      <td>90.3</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>99.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>14.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>31605</td>\n",
       "      <td>102.930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,255,372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.46</td>\n",
       "      <td>19</td>\n",
       "      <td>6.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>40.4</td>\n",
       "      <td>27.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>82.3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.91</td>\n",
       "      <td>474.0</td>\n",
       "      <td>2.005124</td>\n",
       "      <td>10.9</td>\n",
       "      <td>72.8</td>\n",
       "      <td>37.8</td>\n",
       "      <td>1743690.0</td>\n",
       "      <td>5.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.88</td>\n",
       "      <td>91.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>97.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>31.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>33346</td>\n",
       "      <td>104.450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10,032,996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  year  std_total  std_exp  hiv  smoke  drink  stress  depress  \\\n",
       "0            0  2000        NaN      NaN    2    NaN    NaN     NaN      NaN   \n",
       "1            1  2001        NaN      NaN    6    NaN    NaN     NaN      NaN   \n",
       "2            2  2002      0.028      NaN    5    NaN    NaN     NaN      NaN   \n",
       "3            3  2003      0.021      NaN    6    NaN    NaN     NaN      NaN   \n",
       "4            4  2004      0.014      NaN   12    NaN    NaN     NaN      NaN   \n",
       "5            5  2005      0.009      NaN   16    NaN    NaN     NaN      NaN   \n",
       "6            6  2006      0.006     0.13   13   12.8   28.6    46.5     41.4   \n",
       "7            7  2007      0.006     0.12   17   13.3   27.8    46.5     41.3   \n",
       "8            8  2008      0.006     0.11   20   12.8   24.5    43.7     38.8   \n",
       "9            9  2009      0.005     0.10   27   12.8   21.1    43.2     37.5   \n",
       "10          10  2010      0.005     0.09   28   12.1   21.1    43.8     37.4   \n",
       "11          11  2011      0.006     0.11   40   12.1   20.6    42.0     32.8   \n",
       "12          12  2012      0.006     0.13   32   11.4   19.4    41.9     30.5   \n",
       "13          13  2013      0.006     0.11   53    9.7   16.3    41.4     30.9   \n",
       "14          14  2014      0.007     0.13   40    9.2   16.7    37.0     26.7   \n",
       "15          15  2015      0.013     0.26   42    7.8   16.7    35.4     23.6   \n",
       "16          16  2016      0.018     0.39   36    6.3   15.0    37.4     25.5   \n",
       "17          17  2017      0.018     0.35   34    6.4   16.1    37.2     25.1   \n",
       "18          18  2018      0.026     0.46   19    6.7   16.9    40.4     27.1   \n",
       "\n",
       "    sex_frequency  contraception  abortion  obesity  teen_crime  tuberculosis  \\\n",
       "0             NaN           79.3       NaN      NaN         NaN           NaN   \n",
       "1             NaN            NaN       NaN      NaN         NaN        2875.0   \n",
       "2             NaN            NaN       NaN      NaN         NaN        2345.0   \n",
       "3             NaN           84.5       NaN      NaN         NaN        2251.0   \n",
       "4             NaN            NaN       NaN      NaN         NaN        2217.0   \n",
       "5             NaN            NaN       NaN      NaN         NaN        2258.0   \n",
       "6             5.1           79.6       NaN      5.9         NaN        2537.0   \n",
       "7             5.2            NaN       NaN      5.3         NaN        2611.0   \n",
       "8             5.1            NaN       NaN      5.3       18.03        2256.0   \n",
       "9             5.1           80.0       NaN      5.1       17.33        2421.0   \n",
       "10            5.3            NaN     148.0      5.3       13.90        2338.0   \n",
       "11            4.9            NaN     143.0      5.6       12.97        2335.0   \n",
       "12            4.3           77.1     129.0      6.2       16.60        1829.0   \n",
       "13            5.3            NaN     126.0      6.6       14.56        1436.0   \n",
       "14            5.3            NaN      95.0      6.9       13.16        1246.0   \n",
       "15            5.0           79.6      83.0      7.5       14.05        1142.0   \n",
       "16            4.6            NaN      68.0      9.1       13.93         852.0   \n",
       "17            5.2            NaN      57.0     10.0       13.72         697.0   \n",
       "18            5.7           82.3      45.0     10.8       12.91         474.0   \n",
       "\n",
       "    pre_puberty  single  private_edu  exercise3_week  \\\n",
       "0           NaN     NaN          NaN             NaN   \n",
       "1           NaN     NaN          NaN             NaN   \n",
       "2           NaN     NaN          NaN             NaN   \n",
       "3           NaN     NaN          NaN             NaN   \n",
       "4           NaN     NaN          NaN             NaN   \n",
       "5           NaN     8.6          NaN            32.5   \n",
       "6           NaN     8.8          NaN            31.9   \n",
       "7           NaN     8.9         77.0            29.9   \n",
       "8           NaN     9.0         75.1            31.8   \n",
       "9           NaN     9.1         75.0            31.6   \n",
       "10     0.413820     9.2         73.6            33.0   \n",
       "11     0.692249     9.3         71.7            34.1   \n",
       "12     0.858238     9.9         69.4            33.6   \n",
       "13     1.065779    10.2         68.8            35.9   \n",
       "14     1.204761    10.5         68.6            37.2   \n",
       "15     1.328386    10.8         68.8            37.9   \n",
       "16     1.575468    10.8         67.8            37.7   \n",
       "17     1.800836    10.9         71.2            37.3   \n",
       "18     2.005124    10.9         72.8            37.8   \n",
       "\n",
       "    basic_livelihood_security_recipient  culture_fac  welfare_fac  sports_fac  \\\n",
       "0                                   NaN          NaN          NaN         NaN   \n",
       "1                             1419995.0          NaN          NaN         NaN   \n",
       "2                             1351185.0          NaN          NaN         NaN   \n",
       "3                             1374405.0         2.24         2.24       90.04   \n",
       "4                             1424088.0         2.41         2.52       85.77   \n",
       "5                             1513352.0         2.66         3.21       87.54   \n",
       "6                             1534950.0         2.92         4.05       88.11   \n",
       "7                             1549848.0         3.29         4.81       92.96   \n",
       "8                             1529939.0         3.51         6.54      102.16   \n",
       "9                             1568533.0         4.08         8.37      108.19   \n",
       "10                            1549820.0         3.92        10.74      110.16   \n",
       "11                            1469254.0         4.08        11.01      111.97   \n",
       "12                            1394042.0         4.28        11.61      110.74   \n",
       "13                            1350891.0         4.64        12.42      109.74   \n",
       "14                            1328713.0         4.91        13.07      110.33   \n",
       "15                            1646363.0         5.04        13.56      108.40   \n",
       "16                            1630614.0         5.14        14.15      112.81   \n",
       "17                            1581646.0         5.31        14.40      113.72   \n",
       "18                            1743690.0         5.45          NaN         NaN   \n",
       "\n",
       "    park  doctor  internet  spam_email  spam_text  rainy  tropical  heat  \\\n",
       "0    NaN     NaN      44.7         NaN        NaN    NaN       NaN   NaN   \n",
       "1    NaN     NaN      56.6         NaN        NaN    NaN       NaN   NaN   \n",
       "2    NaN     NaN      59.4         NaN        NaN  104.7       3.2   5.9   \n",
       "3    NaN     NaN      65.5         NaN        NaN  120.2       1.4   1.6   \n",
       "4    NaN     NaN      70.2         NaN        NaN  100.9       4.6  16.0   \n",
       "5    NaN     NaN      72.8         NaN        NaN  102.2       5.7  10.6   \n",
       "6    NaN     NaN      74.1         NaN        NaN  103.6       5.7  14.4   \n",
       "7    NaN    2.10      75.5        0.90       0.26  113.6       7.0   9.8   \n",
       "8   10.3    2.23      76.5        0.23       0.08  101.2       6.6  12.5   \n",
       "9    8.1    2.31      77.2        0.12       0.06  105.5       2.9   4.2   \n",
       "10   8.4    2.36      77.8        0.93       0.05  126.2      12.7  13.9   \n",
       "11   8.3    2.42      78.0        1.68       0.03  113.0       6.4   7.5   \n",
       "12   8.9    2.47      78.4        0.62       0.04  116.0      10.2  15.0   \n",
       "13   8.6    2.57      82.1        0.23       0.07  110.4      15.9  18.5   \n",
       "14   8.6    2.62      83.6        0.20       0.01  111.9       3.3   7.4   \n",
       "15   8.8    2.68      85.1        0.14       0.00  112.8       4.9  10.1   \n",
       "16   9.2    2.74      88.3        0.38       0.02  109.4      10.8  22.4   \n",
       "17   9.6    2.82      90.3        0.21       0.01   99.5      10.8  14.4   \n",
       "18  10.1    2.88      91.5        0.14       0.01   97.6      17.7  31.5   \n",
       "\n",
       "    temp_avg  temp_low  temp_high  per_capita_income  consumer_price_index  \\\n",
       "0        NaN       NaN        NaN              12261                66.572   \n",
       "1        NaN       NaN        NaN              11563                69.279   \n",
       "2       12.6       7.8       18.1              13164                71.193   \n",
       "3       12.5       8.0       17.7              14669                73.695   \n",
       "4       13.2       8.2       19.0              16506                76.341   \n",
       "5       12.3       7.6       17.9              19399                78.444   \n",
       "6       12.9       8.3       18.3              21727                80.202   \n",
       "7       13.2       8.7       18.7              24088                82.235   \n",
       "8       12.9       8.2       18.5              21340                86.079   \n",
       "9       13.0       8.2       18.6              19152                88.452   \n",
       "10      12.7       8.1       17.9              23083                91.051   \n",
       "11      12.4       7.8       17.7              25100                94.717   \n",
       "12      12.3       7.8       17.6              25458                96.789   \n",
       "13      12.9       8.1       18.4              27178                98.048   \n",
       "14      13.1       8.4       18.6              29242                99.298   \n",
       "15      13.4       8.7       18.8              28724               100.000   \n",
       "16      13.6       9.0       18.9              29287               100.970   \n",
       "17      13.1       8.1       18.7              31605               102.930   \n",
       "18      13.0       8.2       18.6              33346               104.450   \n",
       "\n",
       "     gini    cosmetic  \n",
       "0     NaN         NaN  \n",
       "1     NaN         NaN  \n",
       "2     NaN         NaN  \n",
       "3     NaN         NaN  \n",
       "4     NaN         NaN  \n",
       "5     NaN         NaN  \n",
       "6     NaN         NaN  \n",
       "7     NaN   4,356,287  \n",
       "8     NaN   5,104,830  \n",
       "9     NaN   5,534,176  \n",
       "10  0.310   6,308,350  \n",
       "11  0.311   6,589,773  \n",
       "12  0.307   7,022,087  \n",
       "13  0.302   7,631,515  \n",
       "14  0.302   8,177,896  \n",
       "15  0.295   9,035,455  \n",
       "16  0.304   9,545,681  \n",
       "17    NaN   9,255,372  \n",
       "18    NaN  10,032,996  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pr=pd.read_csv('prep 합친거.csv')\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\missingpy\\knnimpute.py:224: UserWarning: There are rows with more than 50.0% missing values. These rows are not included as donor neighbors.\n",
      "  .format(self.row_max_missing * 100))\n",
      "C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\missingpy\\knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n",
      "  .format(self.row_max_missing * 100))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8.84666667],\n",
       "       [ 8.84666667],\n",
       "       [ 8.84666667],\n",
       "       [ 2.24      ],\n",
       "       [ 2.52      ],\n",
       "       [ 3.21      ],\n",
       "       [ 4.05      ],\n",
       "       [ 4.81      ],\n",
       "       [ 6.54      ],\n",
       "       [ 8.37      ],\n",
       "       [10.74      ],\n",
       "       [11.01      ],\n",
       "       [11.61      ],\n",
       "       [12.42      ],\n",
       "       [13.07      ],\n",
       "       [13.56      ],\n",
       "       [14.15      ],\n",
       "       [14.4       ],\n",
       "       [ 8.84666667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN으로 결측치 처리하기\n",
    "welfac = pr['welfare_fac']\n",
    "welfac = pd.DataFrame(welfac)\n",
    "\n",
    "# import knnimpute\n",
    "from missingpy import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "welfac_new = imputer.fit_transform(welfac)\n",
    "welfac_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 0.22.1.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "# pip freeze | grep scikit-learn\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\missingpy\\pairwise_external.py:135: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "C:\\Users\\ICT01_04\\Anaconda3\\lib\\site-packages\\missingpy\\pairwise_external.py:138: FutureWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  warn_on_dtype=warn_on_dtype, estimator=estimator)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 4. ],\n",
       "       [3. , 4. , 3. ],\n",
       "       [5.5, 6. , 5. ],\n",
       "       [8. , 8. , 7. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from missingpy import KNNImputer\n",
    "nan = np.nan\n",
    "X = [[1, 2, nan], [3, 4, 3], [nan, 6, 5], [8, 8, 7]]\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "imputer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
